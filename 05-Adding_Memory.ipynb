{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01a8b5c0-87cb-4302-8e3c-dc809d0039fb",
   "metadata": {},
   "source": [
    "# Understanding Memory in LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f73380-6395-4e9f-9c83-3f47a5d7e292",
   "metadata": {},
   "source": [
    "In the previous Notebook, we successfully explored how OpenAI models can enhance the results from Azure Cognitive Search. \n",
    "\n",
    "However, we have yet to discover how to engage in a conversation with the LLM. With [Bing Chat](http://chat.bing.com/), for example, this is possible, as it can understand and reference the previous responses.\n",
    "\n",
    "There is a common misconception that GPT models have memory. This is not true. While they possess knowledge, they do not retain information from previous questions asked to them.\n",
    "\n",
    "In this Notebook, our goal is to illustrate how we can effectively \"endow the LLM with memory\" by employing prompts and context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "733c782e-204c-47d0-8dae-c9df7091ab23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from openai.error import OpenAIError\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.memory import CosmosDBChatMessageHistory\n",
    "\n",
    "from IPython.display import Markdown, HTML, display  \n",
    "\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "\n",
    "#custom libraries that we will use later in the app\n",
    "from common.utils import (\n",
    "    get_search_results,\n",
    "    update_vector_indexes,\n",
    "    model_tokens_limit,\n",
    "    num_tokens_from_docs,\n",
    "    num_tokens_from_string,\n",
    "    get_answer,\n",
    ")\n",
    "\n",
    "from common.prompts import COMBINE_CHAT_PROMPT_TEMPLATE\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"credentials.env\")\n",
    "\n",
    "import logging\n",
    "\n",
    "# Get the root logger\n",
    "logger = logging.getLogger()\n",
    "# Set the logging level to a higher level to ignore INFO messages\n",
    "logger.setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bc63c55-a57d-49a7-b6c7-0f18bca8199e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the ENV variables that Langchain needs to connect to Azure OpenAI\n",
    "os.environ[\"OPENAI_API_BASE\"] = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.environ[\"AZURE_OPENAI_API_KEY\"]\n",
    "os.environ[\"OPENAI_API_VERSION\"] = os.environ[\"AZURE_OPENAI_API_VERSION\"]\n",
    "os.environ[\"OPENAI_API_TYPE\"] = \"azure\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc72b22-11c2-4df0-91b8-033d01829663",
   "metadata": {},
   "source": [
    "### Let's start with the basics\n",
    "Let's use a very simple example to see if the GPT model of Azure OpenAI have memory. We again will be using langchain to simplify our code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3eef5dc9-8b80-4085-980c-865fa41fa1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION = \"Tell me some use cases for reinforcement learning\"\n",
    "FOLLOW_UP_QUESTION = \"Give me the main points of our conversation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a00181d5-bd76-4ce4-a256-75ac5b58c60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "MODEL = \"gpt-35-turbo\"\n",
    "COMPLETION_TOKENS = 500\n",
    "# Create an OpenAI instance\n",
    "llm = AzureChatOpenAI(deployment_name=MODEL, temperature=0.5, max_tokens=COMPLETION_TOKENS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9502d0f1-fddf-40d1-95d2-a1461dcc498a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a very simple prompt template, just the question as is:\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"{question}\",\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5c9903e-15c7-4e05-87a1-58e5a7917ba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "1. Autonomous driving: Reinforcement learning can be used to train self-driving cars to make decisions in real-time, such as navigating through traffic, merging lanes, and avoiding obstacles.\n",
       "\n",
       "2. Robotics: Reinforcement learning can be applied to train robots to perform complex tasks, such as grasping objects, assembling parts, or navigating through cluttered environments.\n",
       "\n",
       "3. Game playing: Reinforcement learning has been successfully used to train agents to play various games, such as chess, Go, poker, and video games. These agents can learn strategies and tactics by playing against themselves or human players.\n",
       "\n",
       "4. Resource management: Reinforcement learning can be used to optimize the allocation of resources in various domains, such as energy management, traffic control, or supply chain management. The agent can learn to make decisions that maximize efficiency and minimize costs.\n",
       "\n",
       "5. Personalized recommendation systems: Reinforcement learning can be used to develop recommendation systems that learn and adapt to individual user preferences over time. The system can learn to recommend products, movies, or music based on user feedback and interactions.\n",
       "\n",
       "6. Healthcare: Reinforcement learning can be applied to optimize treatment plans for patients with chronic diseases. The agent can learn to make decisions about medication dosage, scheduling appointments, or recommending lifestyle changes based on patient outcomes.\n",
       "\n",
       "7. Finance and trading: Reinforcement learning can be used to develop trading strategies that maximize profits in financial markets. The agent can learn to make buy/sell decisions based on market conditions, historical data, and feedback from previous trades.\n",
       "\n",
       "8. Natural language processing: Reinforcement learning can be applied to improve dialogue systems and chatbots. The agent can learn to generate responses that are contextually relevant and engaging based on user interactions and feedback.\n",
       "\n",
       "9. Control systems: Reinforcement learning can be used to optimize control policies for complex systems, such as power grids, manufacturing processes, or chemical plants. The agent can learn to make control decisions that optimize performance and minimize energy consumption.\n",
       "\n",
       "10. Advertising and marketing: Reinforcement learning can be used to optimize advertising campaigns and marketing strategies. The agent can learn to allocate budgets, target specific audiences, and adjust campaign parameters based on user responses and feedback."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's see what the GPT model responds\n",
    "response = chain.run(QUESTION)\n",
    "printmd(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99acaf3c-ce68-4b87-b24a-6065b15ff9a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but as an AI language model, I don't have the capability to remember or recall past conversations. However, if you provide me with the main points or context of our current conversation, I'll be happy to help you with any questions or information you need.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now let's ask a follow up question\n",
    "chain.run(FOLLOW_UP_QUESTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e1c143-c95f-4566-a8b4-af8c42f08dd2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "As you can see, it doesn't remember what it just responded, sometimes it responds based only on the system prompt, or just randomly. This proof that the LLM does NOT have memory and that we need to give the memory as a a conversation history as part of the prompt, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0946ce71-6285-432e-b011-9c2dc1ba7b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_prompt = PromptTemplate(\n",
    "    input_variables=[\"history\", \"question\"],\n",
    "    template=\"\"\"\n",
    "                {history}\n",
    "                Human: {question}\n",
    "                AI:\n",
    "            \"\"\"\n",
    "    )\n",
    "chain = LLMChain(llm=llm, prompt=hist_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d088e51-e5eb-4143-b87d-b2be429eb864",
   "metadata": {},
   "outputs": [],
   "source": [
    "Conversation_history = \"\"\"\n",
    "Human: {question}\n",
    "AI: {response}\n",
    "\"\"\".format(question=QUESTION, response=response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d99e34ad-5539-44dd-b080-3ad05efd2f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "- Reinforcement learning can be used in autonomous driving to train self-driving cars to navigate through traffic, merge lanes, and avoid obstacles.\n",
       "- It can be applied in robotics to train robots to perform complex tasks such as grasping objects, assembling parts, or navigating through cluttered environments.\n",
       "- Reinforcement learning has been successful in training game-playing agents for various games like chess, Go, poker, and video games.\n",
       "- It can be used in resource management to optimize the allocation of resources in domains like energy management, traffic control, or supply chain management.\n",
       "- Reinforcement learning can be applied in personalized recommendation systems to develop systems that learn and adapt to individual user preferences over time.\n",
       "- In healthcare, it can optimize treatment plans for patients with chronic diseases by making decisions about medication dosage, scheduling appointments, or recommending lifestyle changes.\n",
       "- It can be used in finance and trading to develop trading strategies that maximize profits in financial markets.\n",
       "- Reinforcement learning can improve dialogue systems and chatbots in natural language processing by generating contextually relevant and engaging responses.\n",
       "- It can optimize control policies for complex systems like power grids, manufacturing processes, or chemical plants.\n",
       "- Reinforcement learning can be used to optimize advertising campaigns and marketing strategies by allocating budgets, targeting specific audiences, and adjusting campaign parameters based on user responses and feedback."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "printmd(chain.run({\"history\":Conversation_history, \"question\": FOLLOW_UP_QUESTION}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045e5af6-55d6-4353-b3f6-3275c95db00a",
   "metadata": {},
   "source": [
    "**Bingo!**, so we now know how to create a chatbot using LLMs, we just need to keep the state/history of the conversation and pass it as context every time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafd1694-0077-4aa8-bd01-e9f763ce36a3",
   "metadata": {},
   "source": [
    "## Now that we understand the concept of memory via adding history as a context, let's go back to our GPT Smart Search engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba257e86-fd90-4a51-a72d-27000913e8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since Memory adds tokens to the prompt, we would need a better model that allows more space on the prompt\n",
    "MODEL = \"gpt-35-turbo-16k\"\n",
    "COMPLETION_TOKENS = 1000\n",
    "llm = AzureChatOpenAI(deployment_name=MODEL, temperature=0.5, max_tokens=COMPLETION_TOKENS)\n",
    "embedder = OpenAIEmbeddings(deployment=\"text-embedding-ada-002\", chunk_size=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef9f459b-e8b8-40b9-a94d-80c079968594",
   "metadata": {},
   "outputs": [],
   "source": [
    "index1_name = \"cogsrch-index-files\"\n",
    "index2_name = \"cogsrch-index-csv\"\n",
    "index3_name = \"cogsrch-index-books-vector\"\n",
    "text_indexes = [index1_name, index2_name]\n",
    "vector_indexes = [index+\"-vector\" for index in text_indexes] + [index3_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b01852c2-6192-496c-adff-4270f9380469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of results: 5\n",
      "CPU times: user 6.18 s, sys: 140 ms, total: 6.32 s\n",
      "Wall time: 26.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Search in text-based indexes first and update vector indexes\n",
    "k=10 # Top k results per each text-based index\n",
    "ordered_results = get_search_results(QUESTION, text_indexes, k=k, reranker_threshold=1, vector_search=False)\n",
    "update_vector_indexes(ordered_search_results=ordered_results, embedder=embedder)\n",
    "\n",
    "# Search in all vector-based indexes available\n",
    "similarity_k = 5 # top results from multi-vector-index similarity search\n",
    "ordered_results = get_search_results(QUESTION, vector_indexes, k=k, vector_search=True,\n",
    "                                        similarity_k=similarity_k,\n",
    "                                        query_vector = embedder.embed_query(QUESTION))\n",
    "print(\"Number of results:\",len(ordered_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca500dd8-148c-4d8a-b58b-2df4c957459d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the below line if you want to inspect the ordered results\n",
    "# ordered_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b2a3595-c3b7-4376-b9c5-0db7a42b3ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 5\n"
     ]
    }
   ],
   "source": [
    "top_docs = []\n",
    "for key,value in ordered_results.items():\n",
    "    location = value[\"location\"] if value[\"location\"] is not None else \"\"\n",
    "    top_docs.append(Document(page_content=value[\"chunk\"], metadata={\"source\": location+os.environ['BLOB_SAS_TOKEN']}))\n",
    "        \n",
    "print(\"Number of chunks:\",len(top_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c26d7540-feb8-4581-849e-003f4bf2a601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System prompt token count: 2464\n",
      "Max Completion Token count: 1000\n",
      "Combined docs (context) token count: 1985\n",
      "--------\n",
      "Requested token count: 5449\n",
      "Token limit for gpt-35-turbo-16k : 16384\n",
      "Chain Type selected: stuff\n"
     ]
    }
   ],
   "source": [
    "# Calculate number of tokens of our docs\n",
    "if(len(top_docs)>0):\n",
    "    tokens_limit = model_tokens_limit(MODEL) # this is a custom function we created in common/utils.py\n",
    "    prompt_tokens = num_tokens_from_string(COMBINE_CHAT_PROMPT_TEMPLATE) # this is a custom function we created in common/utils.py\n",
    "    context_tokens = num_tokens_from_docs(top_docs) # this is a custom function we created in common/utils.py\n",
    "    \n",
    "    requested_tokens = prompt_tokens + context_tokens + COMPLETION_TOKENS\n",
    "    \n",
    "    chain_type = \"map_reduce\" if requested_tokens > 0.9 * tokens_limit else \"stuff\"  \n",
    "    \n",
    "    print(\"System prompt token count:\",prompt_tokens)\n",
    "    print(\"Max Completion Token count:\", COMPLETION_TOKENS)\n",
    "    print(\"Combined docs (context) token count:\",context_tokens)\n",
    "    print(\"--------\")\n",
    "    print(\"Requested token count:\",requested_tokens)\n",
    "    print(\"Token limit for\", MODEL, \":\", tokens_limit)\n",
    "    print(\"Chain Type selected:\", chain_type)\n",
    "        \n",
    "else:\n",
    "    print(\"NO RESULTS FROM AZURE SEARCH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ce6efa9-2b8f-4810-904d-5986b4ae0372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Reinforcement learning can be used in various use cases, such as:\n",
       "1. Learning prevention strategies for pandemic influenza in a complex epidemiological model with a large state space<sup><a href=\"https://arxiv.org/pdf/2003.13676v1.pdf?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2024-10-02T01:02:07Z&st=2023-08-03T17:02:07Z&spr=https&sig=gLxStXFSY6X29OPpPDpBEhoQDdtJNDrMVExNYJ%2BhmBQ%3D\" target=\"_blank\">[1]</a></sup>.\n",
       "2. Personalized hybrid recommendation algorithm for music based on reinforcement learning, which considers the simulation of interaction process to capture changes in listeners' preferences sensitively<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7206183/?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2024-10-02T01:02:07Z&st=2023-08-03T17:02:07Z&spr=https&sig=gLxStXFSY6X29OPpPDpBEhoQDdtJNDrMVExNYJ%2BhmBQ%3D\" target=\"_blank\">[2]</a></sup>.\n",
       "3. Computing lockdown decisions for individual cities or regions, balancing health and economic considerations, in the context of the Covid-19 pandemic<sup><a href=\"https://arxiv.org/pdf/2003.14093v2.pdf?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2024-10-02T01:02:07Z&st=2023-08-03T17:02:07Z&spr=https&sig=gLxStXFSY6X29OPpPDpBEhoQDdtJNDrMVExNYJ%2BhmBQ%3D\" target=\"_blank\">[3]</a></sup>.\n",
       "4. Speeding up reinforcement learning by separating plannable parts of the world and focusing planning efforts in those areas<sup><a href=\"https://demodatasetsp.blob.core.windows.net/arxivcs/0212/0212025v1.pdf?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2024-10-02T01:02:07Z&st=2023-08-03T17:02:07Z&spr=https&sig=gLxStXFSY6X29OPpPDpBEhoQDdtJNDrMVExNYJ%2BhmBQ%3D\" target=\"_blank\">[4]</a></sup>.\n",
       "5. Maintaining a long-term balance between accuracy and fairness in interactive recommender systems using reinforcement learning<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7206277/?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2024-10-02T01:02:07Z&st=2023-08-03T17:02:07Z&spr=https&sig=gLxStXFSY6X29OPpPDpBEhoQDdtJNDrMVExNYJ%2BhmBQ%3D\" target=\"_blank\">[5]</a></sup>.\n",
       "\n",
       "References:\n",
       "[1] Source: [1]\n",
       "[2] Source: [2]\n",
       "[3] Source: [3]\n",
       "[4] Source: [4]\n",
       "[5] Source: [5]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.4 ms, sys: 44 µs, total: 10.5 ms\n",
      "Wall time: 20.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Get the answer\n",
    "response = get_answer(llm=llm, docs=top_docs, query=QUESTION, language=\"English\", chain_type=chain_type)\n",
    "printmd(response['output_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27501f1b-7db0-4ee3-9cb1-e609254ffa3d",
   "metadata": {},
   "source": [
    "And if we ask the follow up question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5cf5b323-3b9c-479b-8502-acfc4f7915dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I'm sorry, but I couldn't find any extracted parts that contain information about our conversation."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = get_answer(llm=llm, docs=top_docs,  query=FOLLOW_UP_QUESTION, language=\"English\", chain_type=chain_type)\n",
    "printmd(response['output_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035fa6e6-226c-400f-a504-30255385f43b",
   "metadata": {},
   "source": [
    "You might get a different response from above, but it doesn't matter what response you get, it will be based on the context given, not on previous answers.\n",
    "\n",
    "Until now we just have the same as the prior Notebook 03: results from Azure Search enhanced by OpenAI model, with no memory\n",
    "\n",
    "**Now let's add memory to it:**\n",
    "\n",
    "Reference: https://python.langchain.com/docs/modules/memory/how_to/adding_memory_chain_multiple_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d98b876e-d264-48ae-b5ed-9801d6a9152b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Reinforcement learning has various use cases in different domains. Here are some examples:\n",
       "\n",
       "1. **Epidemiology**: Reinforcement learning can be used to learn prevention strategies in the context of pandemic influenza. For example, a study used deep reinforcement learning to automatically learn prevention strategies for pandemic influenza in a meta-population model of Great Britain<sup><a href=\"https://arxiv.org/pdf/2003.13676v1.pdf?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2024-10-02T01:02:07Z&st=2023-08-03T17:02:07Z&spr=https&sig=gLxStXFSY6X29OPpPDpBEhoQDdtJNDrMVExNYJ%2BhmBQ%3D\" target=\"_blank\">[1]</a></sup>. The study demonstrated that deep reinforcement learning can be used to learn mitigation policies in complex epidemiological models.\n",
       "\n",
       "2. **Recommendation Systems**: Reinforcement learning can be used to improve personalized recommendation systems. For example, a study proposed a personalized hybrid recommendation algorithm for music based on reinforcement learning. The algorithm, called PHRR, recommends song sequences that match listeners' preferences better by simulating the interaction process and continuously updating the model based on listeners' preferences<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7206183/?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2024-10-02T01:02:07Z&st=2023-08-03T17:02:07Z&spr=https&sig=gLxStXFSY6X29OPpPDpBEhoQDdtJNDrMVExNYJ%2BhmBQ%3D\" target=\"_blank\">[2]</a></sup>.\n",
       "\n",
       "3. **Public Health Policy**: Reinforcement learning can be used to compute lockdown decisions for individual cities or regions while balancing health and economic considerations. This approach allows for quantitative decision-making by learning policies based on disease parameters and population characteristics<sup><a href=\"https://arxiv.org/pdf/2003.14093v2.pdf?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2024-10-02T01:02:07Z&st=2023-08-03T17:02:07Z&spr=https&sig=gLxStXFSY6X29OPpPDpBEhoQDdtJNDrMVExNYJ%2BhmBQ%3D\" target=\"_blank\">[3]</a></sup>. This approach provides a viable quantitative approach towards lockdown decisions.\n",
       "\n",
       "These are just a few examples of the use cases for reinforcement learning. It can be applied in various other domains such as robotics, finance, gaming, and more. Let me know if you have any other questions!\n",
       "\n",
       "References:\n",
       "1. [1]\n",
       "2. [2]\n",
       "3. [3]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# memory object, which is neccessary to track the inputs/outputs and hold a conversation.\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\",input_key=\"question\")\n",
    "\n",
    "response = get_answer(llm=llm, docs=top_docs, query=QUESTION, language=\"English\", chain_type=chain_type, \n",
    "                        memory=memory)\n",
    "printmd(response['output_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf28927b-d9ee-4412-bb07-13e055e832a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Based on our conversation, here are the main points:\n",
       "\n",
       "1. Reinforcement learning can be used in epidemiology to learn prevention strategies for pandemic influenza in complex epidemiological models. It has been demonstrated that deep reinforcement learning can be used to learn mitigation policies in these models<sup><a href=\"https://arxiv.org/pdf/2003.13676v1.pdf?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2024-10-02T01:02:07Z&st=2023-08-03T17:02:07Z&spr=https&sig=gLxStXFSY6X29OPpPDpBEhoQDdtJNDrMVExNYJ%2BhmBQ%3D\" target=\"_blank\">[1]</a></sup>.\n",
       "\n",
       "2. Reinforcement learning can be applied to improve personalized recommendation systems, such as music recommendation algorithms. These algorithms use reinforcement learning to simulate the interaction process and continuously update the model based on users' preferences<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7206183/?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2024-10-02T01:02:07Z&st=2023-08-03T17:02:07Z&spr=https&sig=gLxStXFSY6X29OPpPDpBEhoQDdtJNDrMVExNYJ%2BhmBQ%3D\" target=\"_blank\">[2]</a></sup>.\n",
       "\n",
       "3. Reinforcement learning can be used to compute lockdown decisions for individual cities or regions in the context of the COVID-19 pandemic. This approach balances health and economic considerations by learning policies based on disease parameters and population characteristics<sup><a href=\"https://arxiv.org/pdf/2003.14093v2.pdf?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2024-10-02T01:02:07Z&st=2023-08-03T17:02:07Z&spr=https&sig=gLxStXFSY6X29OPpPDpBEhoQDdtJNDrMVExNYJ%2BhmBQ%3D\" target=\"_blank\">[3]</a></sup>.\n",
       "\n",
       "These are the main points we discussed during our conversation. Let me know if there's anything else I can help you with!\n",
       "\n",
       "References:\n",
       "1. [1]\n",
       "2. [2]\n",
       "3. [3]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now we add a follow up question:\n",
    "response = get_answer(llm=llm, docs=top_docs, query=FOLLOW_UP_QUESTION, language=\"English\", chain_type=chain_type, \n",
    "                      memory=memory)\n",
    "printmd(response['output_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3830b0b8-0ca2-4d0a-9747-f6273368002b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Based on our conversation, here are the main points:\n",
       "\n",
       "1. Reinforcement learning can be used in epidemiology to learn prevention strategies for pandemic influenza in complex epidemiological models. It has been demonstrated that deep reinforcement learning can be used to learn mitigation policies in these models<sup><a href=\"https://arxiv.org/pdf/2003.13676v1.pdf?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2024-10-02T01:02:07Z&st=2023-08-03T17:02:07Z&spr=https&sig=gLxStXFSY6X29OPpPDpBEhoQDdtJNDrMVExNYJ%2BhmBQ%3D\" target=\"_blank\">[1]</a></sup>.\n",
       "\n",
       "2. Reinforcement learning can be applied to improve personalized recommendation systems, such as music recommendation algorithms. These algorithms use reinforcement learning to simulate the interaction process and continuously update the model based on users' preferences<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7206183/?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2024-10-02T01:02:07Z&st=2023-08-03T17:02:07Z&spr=https&sig=gLxStXFSY6X29OPpPDpBEhoQDdtJNDrMVExNYJ%2BhmBQ%3D\" target=\"_blank\">[2]</a></sup>.\n",
       "\n",
       "3. Reinforcement learning can be used to compute lockdown decisions for individual cities or regions in the context of the COVID-19 pandemic. This approach balances health and economic considerations by learning policies based on disease parameters and population characteristics<sup><a href=\"https://arxiv.org/pdf/2003.14093v2.pdf?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2024-10-02T01:02:07Z&st=2023-08-03T17:02:07Z&spr=https&sig=gLxStXFSY6X29OPpPDpBEhoQDdtJNDrMVExNYJ%2BhmBQ%3D\" target=\"_blank\">[3]</a></sup>.\n",
       "\n",
       "4. Fairness in recommendation systems has gained attention, and there are reinforcement learning-based frameworks that aim to dynamically maintain a balance between accuracy and fairness in interactive recommender systems<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7206277/?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2024-10-02T01:02:07Z&st=2023-08-03T17:02:07Z&spr=https&sig=gLxStXFSY6X29OPpPDpBEhoQDdtJNDrMVExNYJ%2BhmBQ%3D\" target=\"_blank\">[4]</a></sup>.\n",
       "\n",
       "These are the main points we discussed during our conversation. Let me know if there's anything else I can help you with!\n",
       "\n",
       "References:\n",
       "1. [1]\n",
       "2. [2]\n",
       "3. [3]\n",
       "4. [4]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Another follow up query\n",
    "response = get_answer(llm=llm, docs=top_docs, query=\"Thank you\", language=\"English\", chain_type=chain_type,  \n",
    "                      memory=memory)\n",
    "printmd(response['output_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111e732b-3c8c-4df3-8fcb-c3d01e7bec74",
   "metadata": {},
   "source": [
    "You might get a different answer on the above cell, and it is ok, this bot is not yet well configured to answer any question that is not related to its knowledge base, including salutations.\n",
    "\n",
    "Let's check our memory to see that it's keeping the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1279692c-7eb0-4300-8a66-c7025f02c318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: Tell me some use cases for reinforcement learning\\nAI: Reinforcement learning has various use cases in different domains. Here are some examples:\\n\\n1. **Epidemiology**: Reinforcement learning can be used to learn prevention strategies in the context of pandemic influenza. For example, a study used deep reinforcement learning to automatically learn prevention strategies for pandemic influenza in a meta-population model of Great Britain<sup><a href=\"https://arxiv.org/pdf/2003.13676v1.pdf?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2024-10-02T01:02:07Z&st=2023-08-03T17:02:07Z&spr=https&sig=gLxStXFSY6X29OPpPDpBEhoQDdtJNDrMVExNYJ%2BhmBQ%3D\" target=\"_blank\">[1]</a></sup>. The study demonstrated that deep reinforcement learning can be used to learn mitigation policies in complex epidemiological models.\\n\\n2. **Recommendation Systems**: Reinforcement learning can be used to improve personalized recommendation systems. For example, a study proposed a personalized hybrid recommendation algorithm for music based on reinforcement learning. The algorithm, called PHRR, recommends song sequences that match listeners\\' preferences better by simulating the interaction process and continuously updating the model based on listeners\\' preferences<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7206183/?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2024-10-02T01:02:07Z&st=2023-08-03T17:02:07Z&spr=https&sig=gLxStXFSY6X29OPpPDpBEhoQDdtJNDrMVExNYJ%2BhmBQ%3D\" target=\"_blank\">[2]</a></sup>.\\n\\n3. **Public Health Policy**: Reinforcement learning can be used to compute lockdown decisions for individual cities or regions while balancing health and economic considerations. This approach allows for quantitative decision-making by learning policies based on disease parameters and population characteristics<sup><a href=\"https://arxiv.org/pdf/2003.14093v2.pdf?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2024-10-02T01:02:07Z&st=2023-08-03T17:02:07Z&spr=https&sig=gLxStXFSY6X29OPpPDpBEhoQDdtJNDrMVExNYJ%2BhmBQ%3D\" target=\"_blank\">[3]</a></sup>. This approach provides a viable quantitative approach towards lockdown decisions.\\n\\nThese are just a few examples of the use cases for reinforcement learning. It can be applied in various other domains such as robotics, finance, gaming, and more. Let me know if you have any other questions!\\n\\nReferences:\\n1. [1]\\n2. [2]\\n3. [3]\\nHuman: Give me the main points of our conversation\\nAI: Based on our conversation, here are the main points:\\n\\n1. Reinforcement learning can be used in epidemiology to learn prevention strategies for pandemic influenza in complex epidemiological models. It has been demonstrated that deep reinforcement learning can be used to learn mitigation policies in these models<sup><a href=\"https://arxiv.org/pdf/2003.13676v1.pdf?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2024-10-02T01:02:07Z&st=2023-08-03T17:02:07Z&spr=https&sig=gLxStXFSY6X29OPpPDpBEhoQDdtJNDrMVExNYJ%2BhmBQ%3D\" target=\"_blank\">[1]</a></sup>.\\n\\n2. Reinforcement learning can be applied to improve personalized recommendation systems, such as music recommendation algorithms. These algorithms use reinforcement learning to simulate the interaction process and continuously update the model based on users\\' preferences<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7206183/?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2024-10-02T01:02:07Z&st=2023-08-03T17:02:07Z&spr=https&sig=gLxStXFSY6X29OPpPDpBEhoQDdtJNDrMVExNYJ%2BhmBQ%3D\" target=\"_blank\">[2]</a></sup>.\\n\\n3. Reinforcement learning can be used to compute lockdown decisions for individual cities or regions in the context of the COVID-19 pandemic. This approach balances health and economic considerations by learning policies based on disease parameters and population characteristics<sup><a href=\"https://arxiv.org/pdf/2003.14093v2.pdf?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2024-10-02T01:02:07Z&st=2023-08-03T17:02:07Z&spr=https&sig=gLxStXFSY6X29OPpPDpBEhoQDdtJNDrMVExNYJ%2BhmBQ%3D\" target=\"_blank\">[3]</a></sup>.\\n\\nThese are the main points we discussed during our conversation. Let me know if there\\'s anything else I can help you with!\\n\\nReferences:\\n1. [1]\\n2. [2]\\n3. [3]\\nHuman: Thank you\\nAI: Based on our conversation, here are the main points:\\n\\n1. Reinforcement learning can be used in epidemiology to learn prevention strategies for pandemic influenza in complex epidemiological models. It has been demonstrated that deep reinforcement learning can be used to learn mitigation policies in these models<sup><a href=\"https://arxiv.org/pdf/2003.13676v1.pdf?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2024-10-02T01:02:07Z&st=2023-08-03T17:02:07Z&spr=https&sig=gLxStXFSY6X29OPpPDpBEhoQDdtJNDrMVExNYJ%2BhmBQ%3D\" target=\"_blank\">[1]</a></sup>.\\n\\n2. Reinforcement learning can be applied to improve personalized recommendation systems, such as music recommendation algorithms. These algorithms use reinforcement learning to simulate the interaction process and continuously update the model based on users\\' preferences<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7206183/?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2024-10-02T01:02:07Z&st=2023-08-03T17:02:07Z&spr=https&sig=gLxStXFSY6X29OPpPDpBEhoQDdtJNDrMVExNYJ%2BhmBQ%3D\" target=\"_blank\">[2]</a></sup>.\\n\\n3. Reinforcement learning can be used to compute lockdown decisions for individual cities or regions in the context of the COVID-19 pandemic. This approach balances health and economic considerations by learning policies based on disease parameters and population characteristics<sup><a href=\"https://arxiv.org/pdf/2003.14093v2.pdf?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2024-10-02T01:02:07Z&st=2023-08-03T17:02:07Z&spr=https&sig=gLxStXFSY6X29OPpPDpBEhoQDdtJNDrMVExNYJ%2BhmBQ%3D\" target=\"_blank\">[3]</a></sup>.\\n\\n4. Fairness in recommendation systems has gained attention, and there are reinforcement learning-based frameworks that aim to dynamically maintain a balance between accuracy and fairness in interactive recommender systems<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7206277/?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2024-10-02T01:02:07Z&st=2023-08-03T17:02:07Z&spr=https&sig=gLxStXFSY6X29OPpPDpBEhoQDdtJNDrMVExNYJ%2BhmBQ%3D\" target=\"_blank\">[4]</a></sup>.\\n\\nThese are the main points we discussed during our conversation. Let me know if there\\'s anything else I can help you with!\\n\\nReferences:\\n1. [1]\\n2. [2]\\n3. [3]\\n4. [4]'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87405173",
   "metadata": {},
   "source": [
    "## Using CosmosDB as persistent memory\n",
    "\n",
    "In previous cell we have added local RAM memory to our chatbot. However, it is not persistent, it gets deleted once the app user's session is terminated. It is necessary then to use a Database for persistent storage of each of the bot user conversations, not only for Analytics and Auditing, but also if we wisg to provide recommendations. \n",
    "\n",
    "Here we will store the conversation history into CosmosDB for future auditing purpose.\n",
    "We will use a class in LangChain use CosmosDBChatMessageHistory, see [HERE](https://python.langchain.com/en/latest/_modules/langchain/memory/chat_message_histories/cosmos_db.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c7131daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CosmosDB instance from langchain cosmos class.\n",
    "cosmos = CosmosDBChatMessageHistory(\n",
    "    cosmos_endpoint=os.environ['AZURE_COSMOSDB_ENDPOINT'],\n",
    "    cosmos_database=os.environ['AZURE_COSMOSDB_NAME'],\n",
    "    cosmos_container=os.environ['AZURE_COSMOSDB_CONTAINER_NAME'],\n",
    "    connection_string=os.environ['AZURE_COMOSDB_CONNECTION_STRING'],\n",
    "    session_id=\"Agent-Test-Session\" + str(random.randint(1, 1000)),\n",
    "    user_id=\"Agent-Test-User\" + str(random.randint(1, 1000))\n",
    "    )\n",
    "\n",
    "# prepare the cosmosdb instance\n",
    "cosmos.prepare_cosmos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d87cc7c6-5ef1-4492-b133-9f63a392e223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create or Memory Object\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\",input_key=\"question\",chat_memory=cosmos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "27ceb47a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Reinforcement learning (RL) has various use cases in different domains. Here are a few examples:\n",
       "\n",
       "1. **Epidemiology**: RL can be used to learn prevention strategies in the context of pandemic influenza. By constructing epidemiological models and using RL algorithms, prevention strategies can be automatically learned to control the spread of infectious diseases<sup><a href=\"https://arxiv.org/pdf/2003.13676v1.pdf?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2024-10-02T01:02:07Z&st=2023-08-03T17:02:07Z&spr=https&sig=gLxStXFSY6X29OPpPDpBEhoQDdtJNDrMVExNYJ%2BhmBQ%3D\" target=\"_blank\">[1]</a></sup>.\n",
       "\n",
       "2. **Music Recommendation**: RL can enhance personalized music recommendation systems by capturing the changes in listeners' preferences sensitively. By using RL algorithms, song sequences that better match listeners' preferences can be recommended<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7206183/?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2024-10-02T01:02:07Z&st=2023-08-03T17:02:07Z&spr=https&sig=gLxStXFSY6X29OPpPDpBEhoQDdtJNDrMVExNYJ%2BhmBQ%3D\" target=\"_blank\">[2]</a></sup>.\n",
       "\n",
       "3. **Public Health and Economic Policy**: RL can be used to compute lockdown decisions for individual cities or regions while balancing health and economic considerations. By learning policies automatically based on disease parameters and population characteristics, RL algorithms can help in making viable quantitative approaches towards lockdowns<sup><a href=\"https://arxiv.org/pdf/2003.14093v2.pdf?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2024-10-02T01:02:07Z&st=2023-08-03T17:02:07Z&spr=https&sig=gLxStXFSY6X29OPpPDpBEhoQDdtJNDrMVExNYJ%2BhmBQ%3D\" target=\"_blank\">[3]</a></sup>.\n",
       "\n",
       "4. **Planning**: RL can be integrated with planning to speed up learning in uncertain environments. By separating plannable parts of the world and focusing planning efforts in those areas, RL algorithms can find optimal policies and near-optimal macro actions, enabling faster learning<sup><a href=\"https://demodatasetsp.blob.core.windows.net/arxivcs/0212/0212025v1.pdf?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2024-10-02T01:02:07Z&st=2023-08-03T17:02:07Z&spr=https&sig=gLxStXFSY6X29OPpPDpBEhoQDdtJNDrMVExNYJ%2BhmBQ%3D\" target=\"_blank\">[4]</a></sup>.\n",
       "\n",
       "5. **Interactive Recommender Systems**: RL can be used to dynamically maintain a balance between accuracy and fairness in recommendation systems. By compressing user preferences and the system's fairness status into a state representation, RL algorithms can generate recommendations that maximize a designed cumulative reward combining accuracy and fairness<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7206277/?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2024-10-02T01:02:07Z&st=2023-08-03T17:02:07Z&spr=https&sig=gLxStXFSY6X29OPpPDpBEhoQDdtJNDrMVExNYJ%2BhmBQ%3D\" target=\"_blank\">[5]</a></sup>.\n",
       "\n",
       "These are just a few examples, and RL can be applied to various other domains such as robotics, finance, and gaming to name a few. Let me know if there's anything else I can help with!\n",
       "\n",
       "References:\n",
       "[1]<sup><a href=\"https://arxiv.org/pdf/2003.13676v1.pdf?sv=2022-11-02&ss=bf&srt=sco"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Testing using our Question\n",
    "response = get_answer(llm=llm, docs=top_docs, query=QUESTION, language=\"English\", chain_type=chain_type, \n",
    "                        memory=memory)\n",
    "printmd(response['output_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a5ff826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Based on our conversation, here are the main points:\n",
       "\n",
       "1. Reinforcement learning (RL) has various use cases in different domains.\n",
       "2. In epidemiology, RL can be used to learn prevention strategies for controlling the spread of infectious diseases, such as pandemic influenza<sup><a href=\"https://arxiv.org/pdf/2003.13676v1.pdf?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2024-10-02T01:02:07Z&st=2023-08-03T17:02:07Z&spr=https&sig=gLxStXFSY6X29OPpPDpBEhoQDdtJNDrMVExNYJ%2BhmBQ%3D\" target=\"_blank\">[1]</a></sup>.\n",
       "3. RL can enhance personalized music recommendation systems by capturing changes in listeners' preferences sensitively<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7206183/?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2024-10-02T01:02:07Z&st=2023-08-03T17:02:07Z&spr=https&sig=gLxStXFSY6X29OPpPDpBEhoQDdtJNDrMVExNYJ%2BhmBQ%3D\" target=\"_blank\">[2]</a></sup>.\n",
       "4. RL can be used to compute lockdown decisions for individual cities or regions, balancing health and economic considerations<sup><a href=\"https://arxiv.org/pdf/2003.14093v2.pdf?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2024-10-02T01:02:07Z&st=2023-08-03T17:02:07Z&spr=https&sig=gLxStXFSY6X29OPpPDpBEhoQDdtJNDrMVExNYJ%2BhmBQ%3D\" target=\"_blank\">[3]</a></sup>.\n",
       "5. RL can be integrated with planning to speed up learning in uncertain environments<sup><a href=\"https://demodatasetsp.blob.core.windows.net/arxivcs/0212/0212025v1.pdf?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2024-10-02T01:02:07Z&st=2023-08-03T17:02:07Z&spr=https&sig=gLxStXFSY6X29OPpPDpBEhoQDdtJNDrMVExNYJ%2BhmBQ%3D\" target=\"_blank\">[4]</a></sup>.\n",
       "6. RL can be used in interactive recommender systems to dynamically maintain a balance between accuracy and fairness in recommendations<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7206277/?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2024-10-02T01:02:07Z&st=2023-08-03T17:02:07Z&spr=https&sig=gLxStXFSY6X29OPpPDpBEhoQDdtJNDrMVExNYJ%2BhmBQ%3D\" target=\"_blank\">[5]</a></sup>.\n",
       "\n",
       "These are just a few examples of the use cases of reinforcement learning. RL can also be applied in domains such as robotics, finance, and gaming, among others. Let me know if there's anything else I can help with!\n",
       "\n",
       "References:\n",
       "[1]<sup><a href=\"https://arxiv.org/pdf/2003.13676v1.pdf?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2024-10-02T01:02:07Z&st=2023-08-03T17:02:07Z&spr=https&sig=gLxStXFSY6X29OPpPDpBEhoQDdtJNDrMVExNYJ%2BhmBQ%3D\" target=\"_blank\">[1]</a></sup> [2]<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7206183/?sv=2022-11-02&ss=bf&srt=sco&sp=rlt"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now we add a follow up question:\n",
    "response = get_answer(llm=llm, docs=top_docs, query=FOLLOW_UP_QUESTION, language=\"English\", chain_type=chain_type, \n",
    "                      memory=memory)\n",
    "printmd(response['output_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "be1620fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Based on our conversation, here are the main points:\n",
       "\n",
       "1. Reinforcement learning (RL) has various use cases in different domains.\n",
       "2. In epidemiology, RL can be used to learn prevention strategies for controlling the spread of infectious diseases, such as pandemic influenza[1].\n",
       "3. RL can enhance personalized music recommendation systems by capturing changes in listeners' preferences sensitively[2].\n",
       "4. RL can be used to compute lockdown decisions for individual cities or regions, balancing health and economic considerations[3].\n",
       "5. RL can be integrated with planning to speed up learning in uncertain environments[4].\n",
       "6. RL can be used in interactive recommender systems to dynamically maintain a balance between accuracy and fairness in recommendations[5].\n",
       "\n",
       "These are just a few examples of the use cases of reinforcement learning. RL can also be applied in domains such as robotics, finance, and gaming, among others. Let me know if there's anything else I can help with!\n",
       "\n",
       "References:\n",
       "[1]<sup><a href=\"https://arxiv.org/pdf/2003.13676v1.pdf?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2024-10-02T01:02:07Z&st=2023-08-03T17:02:07Z&spr=https&sig=gLxStXFSY6X29OPpPDpBEhoQDdtJNDrMVExNYJ%2BhmBQ%3D\" target=\"_blank\">[1]</a></sup> [2]<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7206183/?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2024-10-02T01:02:07Z&st=2023-08-03T17:02:07Z&spr=https&sig=gLxStXFSY6X29OPpPDpBEhoQDdtJNDrMVExNYJ%2BhmBQ%3D\" target=\"_blank\">[2]</a></sup> [3]<sup><a href=\"https://arxiv.org/pdf/2003.14093v2.pdf?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2024-10-02T01:02:07Z&st=2023-08-03T17:02:07Z&spr=https&sig=gLxStXFSY6X29OPpPDpBEhoQDdtJNDrMVExNYJ%2BhmBQ%3D\" target=\"_blank\">[3]</a></sup> [4]<sup><a href=\"https://demodatasetsp.blob.core.windows.net/arxivcs/0212/0212025v1.pdf?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2024-10-02T01:02:07Z&st=2023-08-03T17:02:07Z&spr=https&sig=gLxStXFSY6X29OPpPDpBEhoQDdtJNDrMVExNYJ%2BhmBQ%3D\" target=\"_blank\">[4]</a></sup> [5]<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7206277/?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2024-10-02T01:02:07Z&st=2023-08-03T17:02:07Z&spr=https&sig=gLxStXFSY6X29OPpPDpBEhoQDdtJNDrMVExNYJ%2BhmBQ%3D\" target=\"_blank\">[5]</a></sup>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Another follow up query\n",
    "response = get_answer(llm=llm, docs=top_docs, query=\"Thank you\", language=\"English\", chain_type=chain_type,  \n",
    "                      memory=memory)\n",
    "printmd(response['output_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc5ac98",
   "metadata": {},
   "source": [
    "Let's check our Azure CosmosDB to see the whole conversation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e1d7688a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Tell me some use cases for reinforcement learning'),\n",
       " AIMessage(content='Reinforcement learning (RL) has various use cases in different domains. Here are a few examples:\\n\\n1. **Epidemiology**: RL can be used to learn prevention strategies in the context of pandemic influenza. By constructing epidemiological models and using RL algorithms, prevention strategies can be automatically learned to control the spread of infectious diseases<sup><a href=\"https://arxiv.org/pdf/2003.13676v1.pdf?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2024-10-02T01:02:07Z&st=2023-08-03T17:02:07Z&spr=https&sig=gLxStXFSY6X29OPpPDpBEhoQDdtJNDrMVExNYJ%2BhmBQ%3D\" target=\"_blank\">[1]</a></sup>.\\n\\n2. **Music Recommendation**: RL can enhance personalized music recommendation systems by capturing the changes in listeners\\' preferences sensitively. By using RL algorithms, song sequences that better match listeners\\' preferences can be recommended<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7206183/?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2024-10-02T01:02:07Z&st=2023-08-03T17:02:07Z&spr=https&sig=gLxStXFSY6X29OPpPDpBEhoQDdtJNDrMVExNYJ%2BhmBQ%3D\" target=\"_blank\">[2]</a></sup>.\\n\\n3. **Public Health and Economic Policy**: RL can be used to compute lockdown decisions for individual cities or regions while balancing health and economic considerations. By learning policies automatically based on disease parameters and population characteristics, RL algorithms can help in making viable quantitative approaches towards lockdowns<sup><a href=\"https://arxiv.org/pdf/2003.14093v2.pdf?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2024-10-02T01:02:07Z&st=2023-08-03T17:02:07Z&spr=https&sig=gLxStXFSY6X29OPpPDpBEhoQDdtJNDrMVExNYJ%2BhmBQ%3D\" target=\"_blank\">[3]</a></sup>.\\n\\n4. **Planning**: RL can be integrated with planning to speed up learning in uncertain environments. By separating plannable parts of the world and focusing planning efforts in those areas, RL algorithms can find optimal policies and near-optimal macro actions, enabling faster learning<sup><a href=\"https://demodatasetsp.blob.core.windows.net/arxivcs/0212/0212025v1.pdf?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2024-10-02T01:02:07Z&st=2023-08-03T17:02:07Z&spr=https&sig=gLxStXFSY6X29OPpPDpBEhoQDdtJNDrMVExNYJ%2BhmBQ%3D\" target=\"_blank\">[4]</a></sup>.\\n\\n5. **Interactive Recommender Systems**: RL can be used to dynamically maintain a balance between accuracy and fairness in recommendation systems. By compressing user preferences and the system\\'s fairness status into a state representation, RL algorithms can generate recommendations that maximize a designed cumulative reward combining accuracy and fairness<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7206277/?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2024-10-02T01:02:07Z&st=2023-08-03T17:02:07Z&spr=https&sig=gLxStXFSY6X29OPpPDpBEhoQDdtJNDrMVExNYJ%2BhmBQ%3D\" target=\"_blank\">[5]</a></sup>.\\n\\nThese are just a few examples, and RL can be applied to various other domains such as robotics, finance, and gaming to name a few. Let me know if there\\'s anything else I can help with!\\n\\nReferences:\\n[1]<sup><a href=\"https://arxiv.org/pdf/2003.13676v1.pdf?sv=2022-11-02&ss=bf&srt=sco'),\n",
       " HumanMessage(content='Give me the main points of our conversation'),\n",
       " AIMessage(content='Based on our conversation, here are the main points:\\n\\n1. Reinforcement learning (RL) has various use cases in different domains.\\n2. In epidemiology, RL can be used to learn prevention strategies for controlling the spread of infectious diseases, such as pandemic influenza<sup><a href=\"https://arxiv.org/pdf/2003.13676v1.pdf?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2024-10-02T01:02:07Z&st=2023-08-03T17:02:07Z&spr=https&sig=gLxStXFSY6X29OPpPDpBEhoQDdtJNDrMVExNYJ%2BhmBQ%3D\" target=\"_blank\">[1]</a></sup>.\\n3. RL can enhance personalized music recommendation systems by capturing changes in listeners\\' preferences sensitively<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7206183/?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2024-10-02T01:02:07Z&st=2023-08-03T17:02:07Z&spr=https&sig=gLxStXFSY6X29OPpPDpBEhoQDdtJNDrMVExNYJ%2BhmBQ%3D\" target=\"_blank\">[2]</a></sup>.\\n4. RL can be used to compute lockdown decisions for individual cities or regions, balancing health and economic considerations<sup><a href=\"https://arxiv.org/pdf/2003.14093v2.pdf?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2024-10-02T01:02:07Z&st=2023-08-03T17:02:07Z&spr=https&sig=gLxStXFSY6X29OPpPDpBEhoQDdtJNDrMVExNYJ%2BhmBQ%3D\" target=\"_blank\">[3]</a></sup>.\\n5. RL can be integrated with planning to speed up learning in uncertain environments<sup><a href=\"https://demodatasetsp.blob.core.windows.net/arxivcs/0212/0212025v1.pdf?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2024-10-02T01:02:07Z&st=2023-08-03T17:02:07Z&spr=https&sig=gLxStXFSY6X29OPpPDpBEhoQDdtJNDrMVExNYJ%2BhmBQ%3D\" target=\"_blank\">[4]</a></sup>.\\n6. RL can be used in interactive recommender systems to dynamically maintain a balance between accuracy and fairness in recommendations<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7206277/?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2024-10-02T01:02:07Z&st=2023-08-03T17:02:07Z&spr=https&sig=gLxStXFSY6X29OPpPDpBEhoQDdtJNDrMVExNYJ%2BhmBQ%3D\" target=\"_blank\">[5]</a></sup>.\\n\\nThese are just a few examples of the use cases of reinforcement learning. RL can also be applied in domains such as robotics, finance, and gaming, among others. Let me know if there\\'s anything else I can help with!\\n\\nReferences:\\n[1]<sup><a href=\"https://arxiv.org/pdf/2003.13676v1.pdf?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2024-10-02T01:02:07Z&st=2023-08-03T17:02:07Z&spr=https&sig=gLxStXFSY6X29OPpPDpBEhoQDdtJNDrMVExNYJ%2BhmBQ%3D\" target=\"_blank\">[1]</a></sup> [2]<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7206183/?sv=2022-11-02&ss=bf&srt=sco&sp=rlt'),\n",
       " HumanMessage(content='Thank you'),\n",
       " AIMessage(content='Based on our conversation, here are the main points:\\n\\n1. Reinforcement learning (RL) has various use cases in different domains.\\n2. In epidemiology, RL can be used to learn prevention strategies for controlling the spread of infectious diseases, such as pandemic influenza[1].\\n3. RL can enhance personalized music recommendation systems by capturing changes in listeners\\' preferences sensitively[2].\\n4. RL can be used to compute lockdown decisions for individual cities or regions, balancing health and economic considerations[3].\\n5. RL can be integrated with planning to speed up learning in uncertain environments[4].\\n6. RL can be used in interactive recommender systems to dynamically maintain a balance between accuracy and fairness in recommendations[5].\\n\\nThese are just a few examples of the use cases of reinforcement learning. RL can also be applied in domains such as robotics, finance, and gaming, among others. Let me know if there\\'s anything else I can help with!\\n\\nReferences:\\n[1]<sup><a href=\"https://arxiv.org/pdf/2003.13676v1.pdf?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2024-10-02T01:02:07Z&st=2023-08-03T17:02:07Z&spr=https&sig=gLxStXFSY6X29OPpPDpBEhoQDdtJNDrMVExNYJ%2BhmBQ%3D\" target=\"_blank\">[1]</a></sup> [2]<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7206183/?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2024-10-02T01:02:07Z&st=2023-08-03T17:02:07Z&spr=https&sig=gLxStXFSY6X29OPpPDpBEhoQDdtJNDrMVExNYJ%2BhmBQ%3D\" target=\"_blank\">[2]</a></sup> [3]<sup><a href=\"https://arxiv.org/pdf/2003.14093v2.pdf?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2024-10-02T01:02:07Z&st=2023-08-03T17:02:07Z&spr=https&sig=gLxStXFSY6X29OPpPDpBEhoQDdtJNDrMVExNYJ%2BhmBQ%3D\" target=\"_blank\">[3]</a></sup> [4]<sup><a href=\"https://demodatasetsp.blob.core.windows.net/arxivcs/0212/0212025v1.pdf?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2024-10-02T01:02:07Z&st=2023-08-03T17:02:07Z&spr=https&sig=gLxStXFSY6X29OPpPDpBEhoQDdtJNDrMVExNYJ%2BhmBQ%3D\" target=\"_blank\">[4]</a></sup> [5]<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7206277/?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2024-10-02T01:02:07Z&st=2023-08-03T17:02:07Z&spr=https&sig=gLxStXFSY6X29OPpPDpBEhoQDdtJNDrMVExNYJ%2BhmBQ%3D\" target=\"_blank\">[5]</a></sup>')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load message from cosmosdb\n",
    "cosmos.load_messages()\n",
    "cosmos.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e30694-ae2a-47bb-a5c7-db51ecdbba1e",
   "metadata": {},
   "source": [
    "![CosmosDB Memory](./images/cosmos-chathistory.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6789cada-23a3-451a-a91a-0906ceb0bd14",
   "metadata": {},
   "source": [
    "# Summary\n",
    "##### Adding memory to our application allows the user to have a conversation, however this feature is not something that comes with the LLM, but instead, memory is something that we must provide to the LLM in form of context of the question.\n",
    "\n",
    "We added persitent memory using CosmosDB.\n",
    "\n",
    "We also can notice that the current chain that we are using is smart, but not that much. Although we have given memory to it, it searches for similar docs everytime, regardless of the input and it struggles to respond to prompts like: Hello, Thank you, Bye, What's your name, What's the weather and any other task that is not search in the knowledge base.\n",
    "\n",
    "\n",
    "## <u>Important Note</u>:<br>\n",
    "As we proceed, while all the code will remain compatible with GPT-3.5 models, we highly recommend transitioning to GPT-4. Here's why:\n",
    "\n",
    "**GPT-3.5-Turbo** can be likened to a 7-year-old child. You can provide it with concise instructions, but it frequently struggles to follow them accurately. Additionally, its limited memory can make sustained conversations challenging.\n",
    "\n",
    "**GPT-3.5-Turbo-16k** resembles the same 7-year-old, but with an increased attention span for longer instructions. However, it still faces difficulties accurately executing them about half the time.\n",
    "\n",
    "**GPT-4** exhibits the capabilities of a 10-12-year-old child. It possesses enhanced reasoning skills and more consistently adheres to instructions. While its memory retention for instructions is moderate, it excels at following them.\n",
    "\n",
    "**GPT-4-32k** is akin to the 10-12-year-old child with an extended memory. It comprehends lengthy sets of instructions and engages in meaningful conversations. Thanks to its robust memory, it offers detailed responses.\n",
    "\n",
    "Understanding this analogy above will become clearer as you complete the final notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c629ebf4-aced-45b7-a6a2-315810d37d48",
   "metadata": {},
   "source": [
    "# NEXT\n",
    "We know now how to do a Smart Search Engine that can power a chatbot!! great!\n",
    "\n",
    "But, does this solve all the possible scenarios that a virtual assistant will require?  **What about if the answer to the Smart Search Engine is not related to text, but instead requires to look into tabular data?** The next notebook explains and solves the tabular problem and the concept of Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4d9da4-3918-4da6-b235-a3320f0dcb12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
